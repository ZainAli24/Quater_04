{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyMVvcDBHUiZvT/vhFePstwt",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ZainAli24/Quater_04/blob/main/OpenRouter_onsite_class01.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **1. OpenRouter: A Unified Interface for 50 Free LLMs :**\n",
        "\n",
        "Haan, aapne OpenRouter ka concept kaafi had tak sahi samjha hai. Main aapki baat ko summarize aur thodi clarity ke saath explain karta hoon:\n",
        "\n",
        "1. **LangChain se Similarity**:  \n",
        "   Aapne bilkul sahi kaha ke OpenRouter ka kaam LangChain se milta-julta hai. LangChain mein hum ek unified interface use karte hain jahan sirf model name (jaise GPT-4, Claude, ya koi aur) aur API key provide karni hoti hai, aur baki ka code same rehta hai, model badalne par code change nahi karna padta. OpenRouter bhi isi tarah ka unified interface provide karta hai, jahan aapko bas model name batana hota hai (jaise Gemini, o1, ya koi aur), aur aapka code model-agnostic rehta hai.\n",
        "\n",
        "2. **OpenRouter ka Key Benefit - Single API Key**:  \n",
        "   Aapka yeh point bhi sahi hai ke OpenRouter ka ek bada faida yeh hai ke aapko har model provider (jaise OpenAI, Anthropic, Google) ke alag-alag API keys use karne ki zarurat nahi. Aap sirf OpenRouter ka ek API key use karte ho, aur usi key ke saath aap OpenRouter ke platform par available koi bhi model select kar sakte ho. Yeh developers ke liye kaam ko bohot simplify karta hai kyunki alag-alag providers ke keys manage karne ka jhanjhat khatam ho jata hai.\n",
        "\n",
        "3. **OpenAI-Compatible API**:  \n",
        "   Aapne yeh bhi mention kiya ke OpenRouter OpenAI ke chat completion API ke saath compatible hai, aur yeh bilkul sahi hai. OpenRouter ne apna API is tarah design kiya hai ke woh OpenAI ke API structure ko follow karta hai. Is wajah se agar aap pehle se OpenAI ke API calls ka code use kar rahe ho, toh OpenRouter ke saath integrate karna bohot asaan ho jata hai. Bas API key aur base URL (`https://openrouter.ai/api/v1`) change karna hota hai, aur model name specify karna hota hai.\n",
        "\n",
        "4. **Model Selection aur Flexibility**:  \n",
        "   OpenRouter ka ek aur faida yeh hai ke ismein aap bohot saare models (open-source aur closed-source dono) ek hi platform par access kar sakte ho. Aapko bas model name batana hota hai (jaise `mistralai/mixtral-8x7b` ya `anthropic/claude-3.5-sonnet`), aur OpenRouter us model ke saath request ko route kar deta hai. Isse aapko alag-alag providers ke APIs ke technical details mein nahi ulajhna padta.\n",
        "\n",
        "### Thodi Aur Clarity:\n",
        "- **API Key ki Baat**: Aapne kaha ke model provider ka API key nahi dena padta, yeh sahi hai, lekin OpenRouter ka apna API key dena zaroori hota hai. Yeh key aap OpenRouter ke website se generate karte ho, aur yeh ek hi key kaafi hoti hai sab models ke liye.\n",
        "- **Cost aur Pricing**: OpenRouter ka ek aur faida yeh hai ke yeh pay-per-token pricing model follow karta hai, aur open-source models ke liye kaafi low-cost hota hai compared to proprietary models. Isse aap apne project ke budget ke hisaab se models choose kar sakte ho.\n",
        "- **Playground aur Testing**: OpenRouter ek playground bhi provide karta hai jahan aap different models ko test kar sakte ho aur unki performance, latency, aur cost compare kar sakte ho.\n",
        "\n",
        "### Aapki Understanding:\n",
        "Aapki understanding bilkul sahi hai ke OpenRouter LangChain ki tarah hi ek abstraction layer provide karta hai, jisse developers ko model switching aur integration mein flexibility milti hai. Yeh OpenAI ke API ke saath compatibility aur single API key ka concept OpenRouter ko bohot developer-friendly banata hai.\n"
      ],
      "metadata": {
        "id": "thiq_QTJ-8rR"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "vL4tLgf1_hUm"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **2. OpenRouters Rata Limits for Free Models :**\n",
        "\n",
        "## **Rate Limits:**\n",
        "### LLMs API rate limits are measured across several dimensions:\n",
        "- ### Requests per minute (RPM)  \n",
        "- ### Tokens per minute (TPM)  \n",
        "- ### Requests per day (RPD)\n",
        "\n",
        "\n",
        "## **OpenRouters Free Models Rata Limits:**\n",
        "### OpenRouter’s free models typically have a global limit of **200 requests per day (RPD)** across all free models, with some also capped at **20 requests per minute (RPM)**, as noted in their documentation. These limits apply to models with IDs ending in :free."
      ],
      "metadata": {
        "id": "saZfFehwEe-C"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "QyGsPNcbFxde"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **3. for use OpenRouter with OpenAI Agents SDK we install openai agents sdk :**\n",
        "```python\n",
        "pip install openai-agents\n",
        "```"
      ],
      "metadata": {
        "id": "XDJ3FPctG8ji"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -Uq openai-agents"
      ],
      "metadata": {
        "id": "zfZfILTeG3b9"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import nest_asyncio\n",
        "nest_asyncio.apply()"
      ],
      "metadata": {
        "id": "2CrZhtRvHO-y"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "OPENROUTER_API_KEY = userdata.get('OPENROUTER_API_KEY')"
      ],
      "metadata": {
        "id": "bO6JrTG0HecV"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **4. OpneRouter ik middle man ki tarah kaam kar rha hai, jo hamari request ko jo specific model choose kia hai wa tak bhejta hai , toh is liye hume request direct us model provider pe nahe karni hume request opnerouter pe karni hai , toh is liye hum `base_url` mien opnerouter ka url denge:**\n",
        "  ```python\n",
        "  BASE_URL = \"https://openrouter.ai/api/v1\"\n",
        "  ```"
      ],
      "metadata": {
        "id": "vx76ROgpICFP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Reference: https://openrouter.ai/docs/quickstart\n",
        "\n",
        "BASE_URL = \"https://openrouter.ai/api/v1\"\n",
        "MODEL = \"google/gemini-2.0-flash-exp:free\"    # use free model.\n",
        "\n",
        "# Some other free models on 26th March:\n",
        "# https://openrouter.ai/deepseek/deepseek-chat-v3-0324:free\n",
        "# https://openrouter.ai/google/gemini-2.5-pro-exp-03-25:free"
      ],
      "metadata": {
        "id": "CjQDe4O2IpGf"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Method 1. Using the OpenRouter API directly:**\n",
        "## **1. OpenRouter ke saath API Request Kaise Bhejte Hain:**\n",
        "\n",
        "OpenRouter ke saath API request bhejne ke liye hum `requests.post` method ka use karte hain. Is process mein hum teen main cheezein bhejte hain:\n",
        "\n",
        "1. **Base URL**: Yeh woh endpoint hai jahan request bheji jati hai. OpenRouter ke liye base URL hota hai:  \n",
        "   `https://openrouter.ai/api/v1/chat/completions`\n",
        "\n",
        "2. **Authorization (API Key)**: Yeh OpenRouter ka API key hota hai, jo headers mein `Authorization` field ke zariye bheja jata hai. Yeh key batata hai ke user authenticated hai ya nahi.  \n",
        "   Format: `\"Authorization\": f\"Bearer {OPENROUTER_API_KEY}\"`\n",
        "\n",
        "3. **Data (JSON Format)**: Yeh woh payload hai jo hum request mein bhejte hain. Ismein do main cheezein hoti hain:\n",
        "   - **Model**: Hum specify karte hain ke kaunsa model use karna hai (jaise `gpt-4`, `claude-3.5-sonnet`, ya `mistralai/mixtral-8x7b`).\n",
        "   - **Messages**: Yeh ek list hoti hai jismein hum model ko bhejna wala message define karte hain. Har message mein `role` (jaise `user`) aur `content` (user ka query) hota hai.\n",
        "\n",
        "### Code Example\n",
        "Yeh raha aapka code, jo OpenRouter ke saath ek POST request bhejta hai:\n",
        "\n",
        "```python\n",
        "import requests\n",
        "import json\n",
        "\n",
        "# Constants\n",
        "BASE_URL = \"https://openrouter.ai/api/v1\"\n",
        "OPENROUTER_API_KEY = \"your_openrouter_api_key_here\"  # Apna API key yahan daalein\n",
        "MODEL = \"anthropic/claude-3.5-sonnet\"  # Yahan desired model ka naam daalein\n",
        "\n",
        "# POST request bhejne ka code\n",
        "response = requests.post(\n",
        "    url=f\"{BASE_URL}/chat/completions\",\n",
        "    headers={\n",
        "        \"Authorization\": f\"Bearer {OPENROUTER_API_KEY}\",\n",
        "    },\n",
        "    data=json.dumps({\n",
        "        \"model\": MODEL,\n",
        "        \"messages\": [\n",
        "            {\n",
        "                \"role\": \"user\",\n",
        "                \"content\": \"you know which car company is making auto drive\"\n",
        "            }\n",
        "        ]\n",
        "    })\n",
        ")\n",
        "\n",
        "# Response print karna\n",
        "print(response.json())\n",
        "```\n",
        "\n",
        "### Code Explanation\n",
        "- **`url`**: Yeh endpoint specify karta hai jahan request jati hai (`/chat/completions`).\n",
        "- **`headers`**: Ismein `Authorization` key ke saath OpenRouter ka API key bheja jata hai.\n",
        "- **`data`**: JSON format mein data bheja jata hai, jismein `model` aur `messages` define kiye jate hain.\n",
        "- **`json.dumps`**: Python dictionary ko JSON string mein convert karta hai.\n",
        "- **`response.json()`**: Server se aaya hua response JSON format mein print karta hai.\n",
        "\n",
        "### Key Points\n",
        "- **Unified Interface**: OpenRouter ka yeh API OpenAI ke chat completion API ke saath compatible hai, isliye agar aap OpenAI ka code use kar rahe hain, toh sirf base URL aur API key change karke OpenRouter use kar sakte hain.\n",
        "- **Error Handling**: Production code mein aapko response status check karna chahiye (jaise `response.status_code == 200`) aur errors ko handle karna chahiye.\n",
        "- **Model Flexibility**: Aap `MODEL` variable mein koi bhi OpenRouter-supported model daal sakte hain bina code change kiye.\n",
        "\n",
        "---\n",
        "\n",
        "### Improvements ke Suggestions\n",
        "1. **Environment Variables**: `OPENROUTER_API_KEY` ko code mein hardcode karne ke bajaye, environment variable (jaise `.env` file) mein store karna better hai for security.\n",
        "   ```python\n",
        "   import os\n",
        "   OPENROUTER_API_KEY = os.getenv(\"OPENROUTER_API_KEY\")\n",
        "   ```\n",
        "2. **Error Handling**:\n",
        "   ```python\n",
        "   if response.status_code == 200:\n",
        "       print(response.json())\n",
        "   else:\n",
        "       print(f\"Error: {response.status_code} - {response.text}\")\n",
        "   ```\n",
        "3. **Multiple Messages**: Aap `messages` list mein multiple messages daal sakte hain, jaise system prompt ya previous conversation:\n",
        "   ```python\n",
        "   \"messages\": [\n",
        "       {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
        "       {\"role\": \"user\", \"content\": \"Which car company is making auto drive?\"}\n",
        "   ]\n",
        "   ```\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "KTxspAXeMZTY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import json\n",
        "\n",
        "response = requests.post(\n",
        "  url=f\"{BASE_URL}/chat/completions\",\n",
        "  headers={\n",
        "    \"Authorization\": f\"Bearer {OPENROUTER_API_KEY}\",\n",
        "  },\n",
        "  data=json.dumps({\n",
        "    \"model\": MODEL,\n",
        "    \"messages\": [\n",
        "      {\n",
        "        \"role\": \"user\",\n",
        "        \"content\":\"you know which car company is making auto driving cars\"\n",
        "      }\n",
        "    ]\n",
        "  })\n",
        ")\n",
        "\n",
        "print(response.json())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4RsZHauoJrlg",
        "outputId": "7b194c01-ee8a-4d0a-eec2-ba7dea5a7db8"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'id': 'gen-1745476841-Ev61QX1JbT3GiD2dZIUW', 'provider': 'Google AI Studio', 'model': 'google/gemini-2.0-flash-exp', 'object': 'chat.completion', 'created': 1745476841, 'choices': [{'logprobs': None, 'finish_reason': 'stop', 'native_finish_reason': 'STOP', 'index': 0, 'message': {'role': 'assistant', 'content': 'Many car companies are developing autonomous driving technology. Here are some of the major players:\\n\\n*   **Tesla:** Known for its Autopilot and Full Self-Driving (FSD) features, though these are currently classified as advanced driver-assistance systems (ADAS) and not full autonomy.\\n*   **Waymo (owned by Alphabet, Google\\'s parent company):** Focuses specifically on autonomous driving technology and operates a robotaxi service in some areas.\\n*   **General Motors (Cruise):** Another company working on autonomous vehicles and operating a robotaxi service, though with some recent setbacks.\\n*   **Ford:** Developing autonomous driving technology, often in partnership with other companies.\\n*   **BMW:** Actively working on autonomous driving features for its future vehicles.\\n*   **Mercedes-Benz:** Offering advanced driver-assistance systems and working towards higher levels of autonomy.\\n*   **Hyundai/Kia:** Investing heavily in autonomous driving and related technologies.\\n*   **Stellantis (Chrysler, Dodge, Jeep, Ram, etc.):** Developing autonomous driving capabilities across its various brands.\\n*   **Nio:** A Chinese electric vehicle company with advanced driver-assistance systems.\\n*   **Xpeng:** Another Chinese EV company actively developing autonomous driving technology.\\n*   **Toyota:** Developing autonomous driving systems, with a focus on safety and reliability.\\n\\nIt\\'s important to note that the level of autonomy varies across these companies and their systems. True \"self-driving\" (Level 5 autonomy, where the car can handle all driving tasks in all conditions) is not yet commercially available. Most systems currently available are Level 2 or Level 3, requiring driver supervision and intervention in many situations.', 'refusal': None, 'reasoning': None}}], 'usage': {'prompt_tokens': 10, 'completion_tokens': 351, 'total_tokens': 361}}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = response.json()\n",
        "print(data['choices'][0]['message']['content'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dXUfF-RRQrxP",
        "outputId": "d77dcef3-e636-43b5-e656-20b8cab47220"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Many car companies are developing autonomous driving technology. Here are some of the major players:\n",
            "\n",
            "*   **Tesla:** Known for its Autopilot and Full Self-Driving (FSD) features, though these are currently classified as advanced driver-assistance systems (ADAS) and not full autonomy.\n",
            "*   **Waymo (owned by Alphabet, Google's parent company):** Focuses specifically on autonomous driving technology and operates a robotaxi service in some areas.\n",
            "*   **General Motors (Cruise):** Another company working on autonomous vehicles and operating a robotaxi service, though with some recent setbacks.\n",
            "*   **Ford:** Developing autonomous driving technology, often in partnership with other companies.\n",
            "*   **BMW:** Actively working on autonomous driving features for its future vehicles.\n",
            "*   **Mercedes-Benz:** Offering advanced driver-assistance systems and working towards higher levels of autonomy.\n",
            "*   **Hyundai/Kia:** Investing heavily in autonomous driving and related technologies.\n",
            "*   **Stellantis (Chrysler, Dodge, Jeep, Ram, etc.):** Developing autonomous driving capabilities across its various brands.\n",
            "*   **Nio:** A Chinese electric vehicle company with advanced driver-assistance systems.\n",
            "*   **Xpeng:** Another Chinese EV company actively developing autonomous driving technology.\n",
            "*   **Toyota:** Developing autonomous driving systems, with a focus on safety and reliability.\n",
            "\n",
            "It's important to note that the level of autonomy varies across these companies and their systems. True \"self-driving\" (Level 5 autonomy, where the car can handle all driving tasks in all conditions) is not yet commercially available. Most systems currently available are Level 2 or Level 3, requiring driver supervision and intervention in many situations.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "gKl_h4PSR4-w"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Method 2. Using OpenRouter with OpenAI Agents SDK:**\n",
        "\n",
        "## **2. OpenAI Agents SDK ke Components aur OpenRouter Integration:**\n",
        "\n",
        "Aapke code aur description ke basis par, yeh raha formatted explanation aur code ka breakdown:\n",
        "\n",
        "#### 1. **`AsyncOpenAI` Class**\n",
        "- **Purpose**: Yeh class OpenAI Agents SDK mein LLMs (Large Language Models) ke saath integration ke liye use hoti hai. Iska kaam hai API requests ko handle karna aur LLM provider (is case mein OpenRouter) ke saath communication karna.\n",
        "- **Inputs**:\n",
        "  - **`api_key`**: OpenRouter ka API key jo authentication ke liye use hota hai.\n",
        "  - **`base_url`**: Yeh woh endpoint hai jahan requests bheji jati hain (OpenRouter ke liye: `https://openrouter.ai/api/v1`).\n",
        "- **Role**: Yeh class OpenAI ke API structure ke saath compatible hai, isliye OpenRouter ke saath seamlessly kaam karta hai.\n",
        "\n",
        "#### 2. **`Agent` Class**\n",
        "- **Purpose**: Yeh class ek agent ko define karti hai jo specific tasks perform karta hai.\n",
        "- **Inputs**:\n",
        "  - **`name`**: Agent ka naam (jaise \"Assistant\").\n",
        "  - **`instructions`**: Agent ke liye instructions ya rules (jaise \"respond only in haikus\").\n",
        "  - **`model`**: Yeh batata hai ke agent kaunsa LLM model use karega (is case mein OpenRouter ka model).\n",
        "- **Role**: Agent ka kaam hai user ke prompts ke basis par intelligent responses generate karna, aur yeh model ke saath integrate hota hai.\n",
        "\n",
        "#### 3. **`OpenAIChatCompletionsModel` Class**\n",
        "- **Purpose**: Yeh class specify karti hai ke kaunsa model use hoga aur kaunsa provider (OpenRouter) us model ko serve karega.\n",
        "- **Inputs**:\n",
        "  - **`model`**: Model ka naam (jaise `anthropic/claude-3.5-sonnet` ya `openai/gpt-4`).\n",
        "  - **`openai_client`**: `AsyncOpenAI` class ka instance, jo API key aur base URL ke saath configure kiya gaya hai.\n",
        "- **Role**: Yeh class model aur provider ke details ko encapsulate karti hai taaki agent ko model ke saath interact karna asaan ho.\n",
        "\n",
        "#### 4. **`set_tracing_disabled` Function**\n",
        "- **Purpose**: Yeh function tracing (agent ke actions ko track karna) ko enable ya disable karta hai.\n",
        "- **Inputs**:\n",
        "  - **`disabled`**: `True` ya `False`. Agar `True` hai, toh tracing band ho jati hai, yani agent ke actions ka detailed log ya tracking nahi hota.\n",
        "- **Role**: Tracing development ke liye useful hoti hai jab aap agent ke har step ko debug karna chahte hain. Production mein tracing disable karna performance ke liye better hota hai.\n",
        "\n",
        "#### 5. **`Runner` Class**\n",
        "- **Purpose**: Yeh class agent ko ek specific prompt ke saath run karti hai aur uska output return karti hai.\n",
        "- **Inputs**:\n",
        "  - **`agent`**: Agent ka instance jo run hoga.\n",
        "  - **`prompt`**: User ka input ya query (jaise \"Tell me about recursion in programming\").\n",
        "- **Role**: Yeh class agent ke execution ko handle karti hai aur final output generate karti hai.\n",
        "\n",
        "---\n",
        "\n",
        "### Code Example\n",
        "Yeh raha aapka code, thoda formatted aur comments ke saath:\n",
        "\n",
        "```python\n",
        "from openai import AsyncOpenAI\n",
        "from agents import Agent, OpenAIChatCompletionsModel, Runner, set_tracing_disabled\n",
        "import asyncio\n",
        "\n",
        "# Constants\n",
        "OPENROUTER_API_KEY = \"your_openrouter_api_key_here\"  # Apna OpenRouter API key yahan daalein\n",
        "BASE_URL = \"https://openrouter.ai/api/v1\"  # OpenRouter ka base URL\n",
        "MODEL = \"anthropic/claude-3.5-sonnet\"  # Desired model ka naam\n",
        "\n",
        "# AsyncOpenAI client initialize karna\n",
        "client = AsyncOpenAI(\n",
        "    api_key=OPENROUTER_API_KEY,\n",
        "    base_url=BASE_URL\n",
        ")\n",
        "\n",
        "# Tracing disable karna (optional, performance ke liye)\n",
        "set_tracing_disabled(disabled=True)\n",
        "\n",
        "# Main async function\n",
        "async def main():\n",
        "    # Agent define karna\n",
        "    agent = Agent(\n",
        "        name=\"Assistant\",\n",
        "        instructions=\"You only respond in haikus.\",  # Agent ke instructions\n",
        "        model=OpenAIChatCompletionsModel(\n",
        "            model=MODEL,\n",
        "            openai_client=client\n",
        "        ),\n",
        "    )\n",
        "\n",
        "    # Agent ko prompt ke saath run karna\n",
        "    result = await Runner.run(\n",
        "        agent,\n",
        "        \"Tell me about recursion in programming.\",\n",
        "    )\n",
        "\n",
        "    # Final output print karna\n",
        "    print(result.final_output)\n",
        "\n",
        "# Async function ko run karna\n",
        "if __name__ == \"__main__\":\n",
        "    asyncio.run(main())\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "### Code Explanation\n",
        "1. **Imports**:\n",
        "   - `AsyncOpenAI`: OpenAI SDK se import kiya gaya hai, jo API requests handle karta hai.\n",
        "   - `Agent`, `OpenAIChatCompletionsModel`, `Runner`, `set_tracing_disabled`: Agents SDK ke components hain.\n",
        "\n",
        "2. **Client Setup**:\n",
        "   - `AsyncOpenAI` ka instance banaya gaya hai jismein OpenRouter ka API key aur base URL pass kiya gaya hai.\n",
        "   - Yeh client model ke saath communication ke liye use hota hai.\n",
        "\n",
        "3. **Tracing**:\n",
        "   - `set_tracing_disabled(True)` se tracing disable ki gayi hai taaki agent ke actions ka log na bane (optional).\n",
        "\n",
        "4. **Agent Definition**:\n",
        "   - `Agent` class ka instance banaya gaya hai jismein:\n",
        "     - `name`: Agent ka naam (\"Assistant\").\n",
        "     - `instructions`: Agent ko bataya gaya hai ke woh sirf haikus mein respond kare.\n",
        "     - `model`: `OpenAIChatCompletionsModel` ka instance pass kiya gaya hai, jismein model name aur client define hain.\n",
        "\n",
        "5. **Runner**:\n",
        "   - `Runner.run` method ke zariye agent ko ek prompt ke saath run kiya gaya hai.\n",
        "   - Prompt: \"Tell me about recursion in programming.\"\n",
        "   - Output: Agent haiku format mein response dega, jo `result.final_output` mein store hota hai.\n",
        "\n",
        "6. **Async Execution**:\n",
        "   - `asyncio.run(main())` se async function ko execute kiya gaya hai kyunki `AsyncOpenAI` aur `Runner` async operations use karte hain.\n",
        "\n",
        "---\n",
        "\n",
        "### Key Points\n",
        "- **OpenRouter Integration**: `AsyncOpenAI` ka use karke OpenRouter ke saath integration bohot asaan hai kyunki OpenRouter OpenAI ke API structure ko follow karta hai.\n",
        "- **Flexibility**: Aap `MODEL` variable change karke koi bhi OpenRouter-supported model (jaise `mistralai/mixtral-8x7b`, `openai/gpt-4o`) use kar sakte hain bina code badle.\n",
        "- **Tracing**: Development ke dauraan tracing enable (`set_tracing_disabled(False)`) karna helpful ho sakta hai taaki aap agent ke har step ko track kar saken.\n",
        "- **Haiku Instruction**: Is example mein agent sirf haikus mein jawab dega, jo ek creative constraint hai.\n",
        "\n",
        "---\n",
        "\n",
        "### Improvements ke Suggestions\n",
        "1. **Error Handling**:\n",
        "   - API calls ya async operations mein errors ko handle karna zaroori hai.\n",
        "   ```python\n",
        "   try:\n",
        "       result = await Runner.run(agent, \"Tell me about recursion in programming.\")\n",
        "       print(result.final_output)\n",
        "   except Exception as e:\n",
        "       print(f\"Error: {e}\")\n",
        "   ```\n",
        "\n",
        "2. **Environment Variables**:\n",
        "   - API key ko secure rakhne ke liye environment variable use karein:\n",
        "   ```python\n",
        "   import os\n",
        "   OPENROUTER_API_KEY = os.getenv(\"OPENROUTER_API_KEY\")\n",
        "   ```\n",
        "\n",
        "3. **Multiple Prompts**:\n",
        "   - Agar aap multiple prompts ya conversation history handle karna chahte hain, toh `Agent` class ke `messages` parameter ko extend kar sakte hain.\n",
        "\n",
        "4. **Logging**:\n",
        "   - Tracing ke alawa, aap custom logging add kar sakte hain taaki agent ke inputs aur outputs ka record rakha ja sake.\n",
        "\n",
        "---\n",
        "\n",
        "### Output Example\n",
        "Agar model `anthropic/claude-3.5-sonnet` hai aur instruction \"You only respond in haikus\" hai, toh prompt \"Tell me about recursion in programming\" ka output kuch aisa ho sakta hai:\n",
        "\n",
        "```\n",
        "Code calls itself back,\n",
        "Solving tasks by breaking down,\n",
        "Base case stops the stack.\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "Aapki understanding bilkul sahi hai, aur yeh code OpenRouter ke saath Agents SDK ko effectively use karta hai.\n"
      ],
      "metadata": {
        "id": "qhvr_b6fTNC0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import asyncio\n",
        "from openai import AsyncOpenAI\n",
        "from agents import Agent, OpenAIChatCompletionsModel, Runner, set_tracing_disabled\n",
        "\n",
        "client = AsyncOpenAI(\n",
        "    api_key=OPENROUTER_API_KEY,\n",
        "    base_url=BASE_URL\n",
        ")\n",
        "\n",
        "set_tracing_disabled(disabled=True)\n",
        "\n",
        "async def main():\n",
        "    # This agent will use the custom LLM provider\n",
        "    agent = Agent(\n",
        "        name=\"Assistant\",\n",
        "        instructions=\"You are my Assistant for any kind of query\",\n",
        "        model=OpenAIChatCompletionsModel(model=MODEL, openai_client=client),\n",
        "    )\n",
        "\n",
        "    result = await Runner.run(\n",
        "        agent,\n",
        "        \"Tell me AI Agents Developer salary in the start beginner level monthly\",\n",
        "    )\n",
        "    print(result.final_output)\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    asyncio.run(main())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E_FUqncbTeuC",
        "outputId": "90a3726b-271f-44cd-8949-efee21421894"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "It's tricky to give you a precise salary for a beginner-level AI Agent Developer, as it can vary significantly based on several factors. Here's a breakdown of the key influencing elements and a general salary range:\n",
            "\n",
            "**Factors Influencing Salary:**\n",
            "\n",
            "*   **Location:** Salaries are heavily influenced by location. Major tech hubs like San Francisco, New York, Seattle, and London will generally have higher salaries compared to smaller cities or areas with a lower cost of living.\n",
            "*   **Company Size and Type:** Large, well-funded tech companies (FAANG, etc.) typically pay more than smaller startups or non-tech companies.\n",
            "*   **Educational Background and Skills:** A degree in Computer Science, Artificial Intelligence, Machine Learning, or a related field is almost essential. Strong programming skills (Python, etc.) and experience with relevant frameworks (TensorFlow, PyTorch, Langchain, etc.) will increase your value.\n",
            "*   **Specific AI Agent Skills:** The demand for certain types of AI agents (e.g., those specializing in customer service, robotics, data analysis) can influence salary. Expertise in natural language processing (NLP), reinforcement learning, or specific AI applications can be a plus.\n",
            "*   **Experience (Even at Entry-Level):** Internships, personal projects, contributions to open-source projects, and even relevant coursework can all be considered as experience. The more demonstrable skills and projects you have, the better.\n",
            "\n",
            "**General Salary Range (Monthly):**\n",
            "\n",
            "Given the above factors, here's a broad estimate for a beginner-level AI Agent Developer's *monthly* salary:\n",
            "\n",
            "*   **United States (Lower End/Smaller Cities):** $4,000 - $6,000 USD\n",
            "*   **United States (Tech Hubs - e.g., San Francisco):** $6,000 - $10,000 USD or more. This could be higher still, particularly if the candidate has strong skills and experience for a \"beginner.\"\n",
            "*   **Europe (Western Europe):** €3,500 - €6,000 EUR (This can vary a lot depending on the country - e.g., Switzerland will be on the high end, while Eastern European countries are generally lower).\n",
            "*   **India:** ₹30,000 - ₹60,000 INR (This can be significantly higher in major tech hubs like Bangalore).\n",
            "\n",
            "*Important Considerations:*\n",
            "\n",
            "*   **Salaries are constantly changing:** The demand for AI skills is high, but market conditions can shift. Always research current salary trends.\n",
            "*   **Total Compensation:** Remember to consider the entire compensation package, including benefits (health insurance, paid time off, retirement plans), stock options (especially in startups), and performance-based bonuses.\n",
            "*   **Negotiation:** Don't be afraid to negotiate, especially if you have strong skills or multiple offers. Research average salaries for similar roles in your area and have a clear understanding of your value.\n",
            "\n",
            "**How to Research Salaries:**\n",
            "\n",
            "*   **Glassdoor:** Provides salary data and company reviews, broken down by location and job title.\n",
            "*   **LinkedIn Salary:** Offers salary insights based on LinkedIn profiles.\n",
            "*   **Levels.fyi:** Focuses on compensation at tech companies, including detailed breakdowns of salary, stock options, and bonuses.\n",
            "*   **Indeed:** Another popular job board with salary information.\n",
            "*   **Salary.com:** Provides salary ranges for various roles based on location.\n",
            "\n",
            "**In Summary:**\n",
            "\n",
            "While a precise number is impossible to give without knowing your specific circumstances, a beginner-level AI Agent Developer can generally expect a starting monthly salary within the ranges provided above, with higher pay in major tech hubs and at larger companies. Be sure to research salaries in your target location and consider the total compensation package when evaluating job offers. Good luck!\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Ns-hrqJtgaMc"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}